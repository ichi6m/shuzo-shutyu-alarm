
※権利関係などが怪しいので、こちらの成績が出次第、コードを大幅に変更する恐れがあります。
# はじめに
こちらは2023年情報メディア創成学類開講 授業「実世界指向システム」で作った作品になります。
課題内容としては、本講義に少しでも関連するプログラム、面白いモノの制作ということでした。

そこで私は、画像認識でメジャーなopencvを用いた「集中力が低下すると松岡修造さんから檄が飛んでくるようなシステム」

名付けて**shuzo-shutyu-alram**を制作しました。
# デモ


https://github.com/ichi6m/shuzo-shutyu-alarm/assets/119064378/feab0942-0dc4-4919-a3a4-745d4780c3e2



# 使い方
1. このリポジトリをクローンする
```
 $ git clone https://github.com/ichi6m/shuzo-shutyu-alarm.git
```
2. 必要なライブラリをインストールする
```
$ pip install -r requirement.txt
```
3. main.py を実行する
```
$ python main.py
```
4. あとはデモ通りなはず


# 背景
## 作ろうとしたきっかけ
作業中集中すべきタスクに集中できていない状況が多々ある。ついスマホを見すぎてしまったり、タスク外の情報をブラウジングしたりしてしまうことはないだろうか。また、20歳を超えると自分に喝を入れてくれるような存在がいなくなり寂しく感じることもあるだろう。

そこで全人類の太陽である**松岡修造**さんから檄が飛んでくるようなシステムを開発しました。

## 関連情報
集中力をセンシングしたり、見える化するような取り組みはいくつかある。[カメラで顔画像を取得して分析したり](https://www.miraxia.com/business/shuchu/)、[脳の活動量を調べたり](https://www.asahi.com/articles/ASM5W74KWM5WULOB01G.html)などがある。

今回の作品では、集中度の指標として瞬きの回数を取り入れることにした。[兜森氏らの研究[1]](https://cir.nii.ac.jp/crid/1050855522084658560)により、集中度が必要とされる条件では瞬きの回数が減少することが確認できた。よって、一分間あたりの瞬きの数がある閾値を超えると、**集中していない**してみようと思う。

# システム概要
### 集中度指標

集中度は主に2つの要素で測っている

- 1分間あたりの瞬きの回数
- 顔の連続トラッキング時間

1分間あたりの瞬きの回数は30回を閾値とする。一般的な瞬きの回数[一分間あたり20-30回[2]](https://www.ikec.jp/mailmag/mailmag-1333/)とされているためである。また、このシステムでは顔をトラッキングし続けるのだが、それも集中度に利用する。顔のトラッキングが5秒間連続できるかどうかも閾値にする。
すなわち、**1分間あたりの瞬きの回数が30回以上 or 顔の連続トラッキングできない時間が5秒経過したら** 集中できていないとみなされるわけだ。

### 檄が飛んでくる
檄が飛んでくる = 突然松岡修造さんからの応援メッセージが流れる

ということです。
sanpleを置いておきます。

https://github.com/ichi6m/shuzo-shutyu-alarm/assets/119064378/42123d08-bb43-4c6e-9f2a-ef807bd7826f



https://github.com/ichi6m/shuzo-shutyu-alarm/assets/119064378/8f8f338a-bf6a-4122-8934-6348d557b5d9



https://github.com/ichi6m/shuzo-shutyu-alarm/assets/119064378/039e5f2b-9939-44cb-bb0d-b08d7367aedc



3つ用意した動画のうちランダムで流れるようになっています。

## 主な制作フロー
1. play_movie.py でMoviePlayerクラスを定義, random_play_movie.pyでそれを継承しRandomMoviePlayerクラスを定義した.
2. 瞬きの回数を数えるプログラムをface_detector.py, eye_tracker.py, resize_face.pyで定義した.瞬きに関するプログラムは[こちら[3]](https://qiita.com/mogamin/items/a65e2eaa4b27aa0a1c23#opencv--dlib%E7%89%88-%E5%AE%9F%E8%A3%85%E3%81%A8%E7%B5%90%E6%9E%9C)を参考にしました。簡単にいうと、opencvとdlibで目の比をリアルタイムで求めるといったことをしています。
3. main.py でこれらを統合し、実際に集中している時には流れず、集中していない時には動画が流れるのかを確認しながら、閾値を調整しました。



# 課題・感想
- main.py のコードがかなり汚くなってしまった。変数が多くなりすぎた。
- python main.py を実行するとlibSDL2はlocalかpygameどっちを通しますか警告が出てしまう -> 環境変数にどっちか通せばいいが、通すとpygameが効かなくなるので困った(対処できずに終わった)
- 動画が流れている時、時間は経つが瞬き検出はしない状態になっているので、正確に1minあたりの瞬き回数数えられているわけではない
- 瞬きだけじゃなくて姿勢推定とか動作検出も組み込みたい
- やはり松岡修造のメッセージは気合が入る
- 最終的にはwebアプリとしてデプロイ目指したいですね。


# 参考
[1][webカメラを用いた瞬き検出による集中度評価](https://cir.nii.ac.jp/crid/1050855522084658560)

[2][142.まばたきについて(池袋サンシャイン通り眼科診療所)](https://www.ikec.jp/mailmag/mailmag-1333/)

[3][眠気を判定！目のまばたき検知をDlibとOpenCVを組み合わせて数十行で作る](https://qiita.com/mogamin/items/a65e2eaa4b27aa0a1c23#opencv--dlib%E7%89%88-%E5%AE%9F%E8%A3%85%E3%81%A8%E7%B5%90%E6%9E%9C)
